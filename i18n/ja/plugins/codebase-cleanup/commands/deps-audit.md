# ä¾å­˜é–¢ä¿‚ç›£æŸ»ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ†æ

ã‚ãªãŸã¯è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³ã€ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã€ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã«ç‰¹åŒ–ã—ãŸä¾å­˜é–¢ä¿‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å°‚é–€å®¶ã§ã™ã€‚æ—¢çŸ¥ã®è„†å¼±æ€§ã€ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å•é¡Œã€å¤ã„ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«ã¤ã„ã¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¾å­˜é–¢ä¿‚ã‚’åˆ†æã—ã€å®Ÿè¡Œå¯èƒ½ãªä¿®å¾©æˆ¦ç•¥ã‚’æä¾›ã—ã¾ã™ã€‚

## ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¾å­˜é–¢ä¿‚ã«ãŠã‘ã‚‹ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã€ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ç«¶åˆã€ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒªã‚¹ã‚¯ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®åŒ…æ‹¬çš„ãªä¾å­˜é–¢ä¿‚åˆ†æã‚’å¿…è¦ã¨ã—ã¦ã„ã¾ã™ã€‚å¯èƒ½ãªé™ã‚Šè‡ªå‹•ä¿®æ­£ã‚’å«ã‚€å®Ÿè¡Œå¯èƒ½ãªã‚¤ãƒ³ã‚µã‚¤ãƒˆã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚

## è¦ä»¶
$ARGUMENTS

## æŒ‡ç¤º

### 1. ä¾å­˜é–¢ä¿‚ã®æ¤œå‡º

ã™ã¹ã¦ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¾å­˜é–¢ä¿‚ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ã‚¤ãƒ³ãƒ™ãƒ³ãƒˆãƒªåŒ–ã—ã¾ã™ï¼š

**å¤šè¨€èªæ¤œå‡º**
```python
import os
import json
import toml
import yaml
from pathlib import Path

class DependencyDiscovery:
    def __init__(self, project_path):
        self.project_path = Path(project_path)
        self.dependency_files = {
            'npm': ['package.json', 'package-lock.json', 'yarn.lock'],
            'python': ['requirements.txt', 'Pipfile', 'Pipfile.lock', 'pyproject.toml', 'poetry.lock'],
            'ruby': ['Gemfile', 'Gemfile.lock'],
            'java': ['pom.xml', 'build.gradle', 'build.gradle.kts'],
            'go': ['go.mod', 'go.sum'],
            'rust': ['Cargo.toml', 'Cargo.lock'],
            'php': ['composer.json', 'composer.lock'],
            'dotnet': ['*.csproj', 'packages.config', 'project.json']
        }

    def discover_all_dependencies(self):
        """
        ç•°ãªã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã«ã‚ãŸã‚‹ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ã‚’æ¤œå‡º
        """
        dependencies = {}

        # NPM/Yarnä¾å­˜é–¢ä¿‚
        if (self.project_path / 'package.json').exists():
            dependencies['npm'] = self._parse_npm_dependencies()

        # Pythonä¾å­˜é–¢ä¿‚
        if (self.project_path / 'requirements.txt').exists():
            dependencies['python'] = self._parse_requirements_txt()
        elif (self.project_path / 'Pipfile').exists():
            dependencies['python'] = self._parse_pipfile()
        elif (self.project_path / 'pyproject.toml').exists():
            dependencies['python'] = self._parse_pyproject_toml()

        # Goä¾å­˜é–¢ä¿‚
        if (self.project_path / 'go.mod').exists():
            dependencies['go'] = self._parse_go_mod()

        return dependencies

    def _parse_npm_dependencies(self):
        """
        NPM package.jsonã¨ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
        """
        with open(self.project_path / 'package.json', 'r') as f:
            package_json = json.load(f)

        deps = {}

        # ç›´æ¥ä¾å­˜é–¢ä¿‚
        for dep_type in ['dependencies', 'devDependencies', 'peerDependencies']:
            if dep_type in package_json:
                for name, version in package_json[dep_type].items():
                    deps[name] = {
                        'version': version,
                        'type': dep_type,
                        'direct': True
                    }

        # æ­£ç¢ºãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãŸã‚ã®ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«è§£æ
        if (self.project_path / 'package-lock.json').exists():
            with open(self.project_path / 'package-lock.json', 'r') as f:
                lock_data = json.load(f)
                self._parse_npm_lock(lock_data, deps)

        return deps
```

**ä¾å­˜é–¢ä¿‚ãƒ„ãƒªãƒ¼åˆ†æ**
```python
def build_dependency_tree(dependencies):
    """
    æ¨ç§»çš„ä¾å­˜é–¢ä¿‚ã‚’å«ã‚€å®Œå…¨ãªä¾å­˜é–¢ä¿‚ãƒ„ãƒªãƒ¼ã‚’æ§‹ç¯‰
    """
    tree = {
        'root': {
            'name': 'project',
            'version': '1.0.0',
            'dependencies': {}
        }
    }

    def add_dependencies(node, deps, visited=None):
        if visited is None:
            visited = set()

        for dep_name, dep_info in deps.items():
            if dep_name in visited:
                # å¾ªç’°ä¾å­˜æ¤œå‡º
                node['dependencies'][dep_name] = {
                    'circular': True,
                    'version': dep_info['version']
                }
                continue

            visited.add(dep_name)

            node['dependencies'][dep_name] = {
                'version': dep_info['version'],
                'type': dep_info.get('type', 'runtime'),
                'dependencies': {}
            }

            # æ¨ç§»çš„ä¾å­˜é–¢ä¿‚ã‚’å†å¸°çš„ã«è¿½åŠ 
            if 'dependencies' in dep_info:
                add_dependencies(
                    node['dependencies'][dep_name],
                    dep_info['dependencies'],
                    visited.copy()
                )

    add_dependencies(tree['root'], dependencies)
    return tree
```

### 2. è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³

è„†å¼±æ€§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å¯¾ã—ã¦ä¾å­˜é–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯ï¼š

**CVEãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯**
```python
import requests
from datetime import datetime

class VulnerabilityScanner:
    def __init__(self):
        self.vulnerability_apis = {
            'npm': 'https://registry.npmjs.org/-/npm/v1/security/advisories/bulk',
            'pypi': 'https://pypi.org/pypi/{package}/json',
            'rubygems': 'https://rubygems.org/api/v1/gems/{package}.json',
            'maven': 'https://ossindex.sonatype.org/api/v3/component-report'
        }

    def scan_vulnerabilities(self, dependencies):
        """
        æ—¢çŸ¥ã®è„†å¼±æ€§ã«ã¤ã„ã¦ä¾å­˜é–¢ä¿‚ã‚’ã‚¹ã‚­ãƒ£ãƒ³
        """
        vulnerabilities = []

        for package_name, package_info in dependencies.items():
            vulns = self._check_package_vulnerabilities(
                package_name,
                package_info['version'],
                package_info.get('ecosystem', 'npm')
            )

            if vulns:
                vulnerabilities.extend(vulns)

        return self._analyze_vulnerabilities(vulnerabilities)

    def _check_package_vulnerabilities(self, name, version, ecosystem):
        """
        ç‰¹å®šãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®è„†å¼±æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        """
        if ecosystem == 'npm':
            return self._check_npm_vulnerabilities(name, version)
        elif ecosystem == 'pypi':
            return self._check_python_vulnerabilities(name, version)
        elif ecosystem == 'maven':
            return self._check_java_vulnerabilities(name, version)

    def _check_npm_vulnerabilities(self, name, version):
        """
        NPMãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®è„†å¼±æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        """
        # npm audit APIã‚’ä½¿ç”¨
        response = requests.post(
            'https://registry.npmjs.org/-/npm/v1/security/advisories/bulk',
            json={name: [version]}
        )

        vulnerabilities = []
        if response.status_code == 200:
            data = response.json()
            if name in data:
                for advisory in data[name]:
                    vulnerabilities.append({
                        'package': name,
                        'version': version,
                        'severity': advisory['severity'],
                        'title': advisory['title'],
                        'cve': advisory.get('cves', []),
                        'description': advisory['overview'],
                        'recommendation': advisory['recommendation'],
                        'patched_versions': advisory['patched_versions'],
                        'published': advisory['created']
                    })

        return vulnerabilities
```

**æ·±åˆ»åº¦åˆ†æ**
```python
def analyze_vulnerability_severity(vulnerabilities):
    """
    æ·±åˆ»åº¦ã§è„†å¼±æ€§ã‚’åˆ†æã—ã¦å„ªå…ˆé †ä½ä»˜ã‘
    """
    severity_scores = {
        'critical': 9.0,
        'high': 7.0,
        'moderate': 4.0,
        'low': 1.0
    }

    analysis = {
        'total': len(vulnerabilities),
        'by_severity': {
            'critical': [],
            'high': [],
            'moderate': [],
            'low': []
        },
        'risk_score': 0,
        'immediate_action_required': []
    }

    for vuln in vulnerabilities:
        severity = vuln['severity'].lower()
        analysis['by_severity'][severity].append(vuln)

        # ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        base_score = severity_scores.get(severity, 0)

        # è¦å› ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢ã‚’èª¿æ•´
        if vuln.get('exploit_available', False):
            base_score *= 1.5
        if vuln.get('publicly_disclosed', True):
            base_score *= 1.2
        if 'remote_code_execution' in vuln.get('description', '').lower():
            base_score *= 2.0

        vuln['risk_score'] = base_score
        analysis['risk_score'] += base_score

        # å³åº§ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³é …ç›®ã‚’ãƒ•ãƒ©ã‚°
        if severity in ['critical', 'high'] or base_score > 8.0:
            analysis['immediate_action_required'].append({
                'package': vuln['package'],
                'severity': severity,
                'action': f"Update to {vuln['patched_versions']}"
            })

    # ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    for severity in analysis['by_severity']:
        analysis['by_severity'][severity].sort(
            key=lambda x: x.get('risk_score', 0),
            reverse=True
        )

    return analysis
```

### 3. ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹

äº’æ›æ€§ã«ã¤ã„ã¦ä¾å­˜é–¢ä¿‚ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚’åˆ†æï¼š

**ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æ¤œå‡º**
```python
class LicenseAnalyzer:
    def __init__(self):
        self.license_compatibility = {
            'MIT': ['MIT', 'BSD', 'Apache-2.0', 'ISC'],
            'Apache-2.0': ['Apache-2.0', 'MIT', 'BSD'],
            'GPL-3.0': ['GPL-3.0', 'GPL-2.0'],
            'BSD-3-Clause': ['BSD-3-Clause', 'MIT', 'Apache-2.0'],
            'proprietary': []
        }

        self.license_restrictions = {
            'GPL-3.0': 'ã‚³ãƒ”ãƒ¼ãƒ¬ãƒ•ãƒˆ - ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰é–‹ç¤ºãŒå¿…è¦',
            'AGPL-3.0': 'å¼·åŠ›ãªã‚³ãƒ”ãƒ¼ãƒ¬ãƒ•ãƒˆ - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä½¿ç”¨ã«ã¯ã‚½ãƒ¼ã‚¹é–‹ç¤ºãŒå¿…è¦',
            'proprietary': 'æ˜ç¤ºçš„ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãªã—ã§ã¯ä½¿ç”¨ä¸å¯',
            'unknown': 'ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãŒä¸æ˜ - æ³•çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå¿…è¦'
        }

    def analyze_licenses(self, dependencies, project_license='MIT'):
        """
        ãƒ©ã‚¤ã‚»ãƒ³ã‚¹äº’æ›æ€§ã‚’åˆ†æ
        """
        issues = []
        license_summary = {}

        for package_name, package_info in dependencies.items():
            license_type = package_info.get('license', 'unknown')

            # ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ä½¿ç”¨ã‚’è¿½è·¡
            if license_type not in license_summary:
                license_summary[license_type] = []
            license_summary[license_type].append(package_name)

            # äº’æ›æ€§ã‚’ãƒã‚§ãƒƒã‚¯
            if not self._is_compatible(project_license, license_type):
                issues.append({
                    'package': package_name,
                    'license': license_type,
                    'issue': f'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ©ã‚¤ã‚»ãƒ³ã‚¹ {project_license} ã¨äº’æ›æ€§ãŒã‚ã‚Šã¾ã›ã‚“',
                    'severity': 'high',
                    'recommendation': self._get_license_recommendation(
                        license_type,
                        project_license
                    )
                })

            # åˆ¶é™çš„ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
            if license_type in self.license_restrictions:
                issues.append({
                    'package': package_name,
                    'license': license_type,
                    'issue': self.license_restrictions[license_type],
                    'severity': 'medium',
                    'recommendation': 'ä½¿ç”¨ã‚’ç¢ºèªã—ã¦ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚’ç¢ºä¿ã—ã¦ãã ã•ã„'
                })

        return {
            'summary': license_summary,
            'issues': issues,
            'compliance_status': 'FAIL' if issues else 'PASS'
        }
```

**ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ**
```markdown
## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ

### ã‚µãƒãƒªãƒ¼
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ©ã‚¤ã‚»ãƒ³ã‚¹**: MIT
- **ç·ä¾å­˜é–¢ä¿‚æ•°**: 245
- **ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å•é¡Œ**: 3
- **ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹çŠ¶æ…‹**: âš ï¸ ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå¿…è¦

### ãƒ©ã‚¤ã‚»ãƒ³ã‚¹åˆ†å¸ƒ
| ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ | ä»¶æ•° | ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ |
|---------|-------|----------|
| MIT | 180 | express, lodash, ... |
| Apache-2.0 | 45 | aws-sdk, ... |
| BSD-3-Clause | 15 | ... |
| GPL-3.0 | 3 | [å•é¡Œ] package1, package2, package3 |
| ä¸æ˜ | 2 | [å•é¡Œ] mystery-lib, old-package |

### ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹å•é¡Œ

#### é«˜æ·±åˆ»åº¦
1. **GPL-3.0ä¾å­˜é–¢ä¿‚**
   - ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: package1, package2, package3
   - å•é¡Œ: GPL-3.0ã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¨äº’æ›æ€§ãŒã‚ã‚Šã¾ã›ã‚“
   - ãƒªã‚¹ã‚¯: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ãŒå¿…è¦ã«ãªã‚‹å¯èƒ½æ€§
   - æ¨å¥¨äº‹é …:
     - MIT/Apacheãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä»£æ›¿å“ã«ç½®ãæ›ãˆ
     - ã¾ãŸã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚’GPL-3.0ã«å¤‰æ›´

#### ä¸­æ·±åˆ»åº¦
2. **ä¸æ˜ãªãƒ©ã‚¤ã‚»ãƒ³ã‚¹**
   - ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: mystery-lib, old-package
   - å•é¡Œ: ãƒ©ã‚¤ã‚»ãƒ³ã‚¹äº’æ›æ€§ã‚’åˆ¤æ–­ã§ãã¾ã›ã‚“
   - ãƒªã‚¹ã‚¯: æ½œåœ¨çš„ãªæ³•çš„ãƒªã‚¹ã‚¯
   - æ¨å¥¨äº‹é …:
     - ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒ†ãƒŠãƒ¼ã«é€£çµ¡
     - ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±ã«ã¤ã„ã¦ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèª
     - æ—¢çŸ¥ã®ä»£æ›¿å“ã¸ã®ç½®ãæ›ãˆã‚’æ¤œè¨
```

### 4. å¤ã„ä¾å­˜é–¢ä¿‚

ä¾å­˜é–¢ä¿‚ã®æ›´æ–°ã‚’ç‰¹å®šã—ã¦å„ªå…ˆé †ä½ä»˜ã‘ï¼š

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³åˆ†æ**
```python
def analyze_outdated_dependencies(dependencies):
    """
    å¤ã„ä¾å­˜é–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯
    """
    outdated = []

    for package_name, package_info in dependencies.items():
        current_version = package_info['version']
        latest_version = fetch_latest_version(package_name, package_info['ecosystem'])

        if is_outdated(current_version, latest_version):
            # ã©ã‚Œã ã‘å¤ã„ã‹ã‚’è¨ˆç®—
            version_diff = calculate_version_difference(current_version, latest_version)

            outdated.append({
                'package': package_name,
                'current': current_version,
                'latest': latest_version,
                'type': version_diff['type'],  # major, minor, patch
                'releases_behind': version_diff['count'],
                'age_days': get_version_age(package_name, current_version),
                'breaking_changes': version_diff['type'] == 'major',
                'update_effort': estimate_update_effort(version_diff),
                'changelog': fetch_changelog(package_name, current_version, latest_version)
            })

    return prioritize_updates(outdated)

def prioritize_updates(outdated_deps):
    """
    è¤‡æ•°ã®è¦å› ã«åŸºã¥ã„ã¦æ›´æ–°ã‚’å„ªå…ˆé †ä½ä»˜ã‘
    """
    for dep in outdated_deps:
        score = 0

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ›´æ–°ãŒæœ€å„ªå…ˆ
        if dep.get('has_security_fix', False):
            score += 100

        # ãƒ¡ã‚¸ãƒ£ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ›´æ–°
        if dep['type'] == 'major':
            score += 20
        elif dep['type'] == 'minor':
            score += 10
        else:
            score += 5

        # çµŒéæ™‚é–“è¦å› 
        if dep['age_days'] > 365:
            score += 30
        elif dep['age_days'] > 180:
            score += 20
        elif dep['age_days'] > 90:
            score += 10

        # é…ã‚Œã¦ã„ã‚‹ãƒªãƒªãƒ¼ã‚¹æ•°
        score += min(dep['releases_behind'] * 2, 20)

        dep['priority_score'] = score
        dep['priority'] = 'critical' if score > 80 else 'high' if score > 50 else 'medium'

    return sorted(outdated_deps, key=lambda x: x['priority_score'], reverse=True)
```

### 5. ä¾å­˜é–¢ä¿‚ã‚µã‚¤ã‚ºåˆ†æ

ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºã¸ã®å½±éŸ¿ã‚’åˆ†æï¼š

**ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºã¸ã®å½±éŸ¿**
```javascript
// NPMãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚µã‚¤ã‚ºã‚’åˆ†æ
const analyzeBundleSize = async (dependencies) => {
    const sizeAnalysis = {
        totalSize: 0,
        totalGzipped: 0,
        packages: [],
        recommendations: []
    };

    for (const [packageName, info] of Object.entries(dependencies)) {
        try {
            // ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸çµ±è¨ˆã‚’å–å¾—
            const response = await fetch(
                `https://bundlephobia.com/api/size?package=${packageName}@${info.version}`
            );
            const data = await response.json();

            const packageSize = {
                name: packageName,
                version: info.version,
                size: data.size,
                gzip: data.gzip,
                dependencyCount: data.dependencyCount,
                hasJSNext: data.hasJSNext,
                hasSideEffects: data.hasSideEffects
            };

            sizeAnalysis.packages.push(packageSize);
            sizeAnalysis.totalSize += data.size;
            sizeAnalysis.totalGzipped += data.gzip;

            // ã‚µã‚¤ã‚ºæ¨å¥¨äº‹é …
            if (data.size > 1000000) { // 1MB
                sizeAnalysis.recommendations.push({
                    package: packageName,
                    issue: 'ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„',
                    size: `${(data.size / 1024 / 1024).toFixed(2)} MB`,
                    suggestion: 'ã‚ˆã‚Šè»½é‡ãªä»£æ›¿å“ã‚’æ¤œè¨ã™ã‚‹ã‹ã€é…å»¶èª­ã¿è¾¼ã¿ã‚’ä½¿ç”¨'
                });
            }
        } catch (error) {
            console.error(`${packageName}ã®åˆ†æã«å¤±æ•—:`, error);
        }
    }

    // ã‚µã‚¤ã‚ºã§ã‚½ãƒ¼ãƒˆ
    sizeAnalysis.packages.sort((a, b) => b.size - a.size);

    // ä¸Šä½ã®å•é¡Œãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è¿½åŠ 
    sizeAnalysis.topOffenders = sizeAnalysis.packages.slice(0, 10);

    return sizeAnalysis;
};
```

### 6. ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

ä¾å­˜é–¢ä¿‚ãƒã‚¤ã‚¸ãƒ£ãƒƒã‚¯ã¨ã‚¿ã‚¤ãƒã‚¹ã‚¯ãƒ¯ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚’ãƒã‚§ãƒƒã‚¯ï¼š

**ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯**
```python
def check_supply_chain_security(dependencies):
    """
    ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
    """
    security_issues = []

    for package_name, package_info in dependencies.items():
        # ã‚¿ã‚¤ãƒã‚¹ã‚¯ãƒ¯ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚’ãƒã‚§ãƒƒã‚¯
        typo_check = check_typosquatting(package_name)
        if typo_check['suspicious']:
            security_issues.append({
                'type': 'typosquatting',
                'package': package_name,
                'severity': 'high',
                'similar_to': typo_check['similar_packages'],
                'recommendation': 'ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã®ã‚¹ãƒšãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„'
            })

        # ãƒ¡ãƒ³ãƒ†ãƒŠãƒ¼å¤‰æ›´ã‚’ãƒã‚§ãƒƒã‚¯
        maintainer_check = check_maintainer_changes(package_name)
        if maintainer_check['recent_changes']:
            security_issues.append({
                'type': 'maintainer_change',
                'package': package_name,
                'severity': 'medium',
                'details': maintainer_check['changes'],
                'recommendation': 'æœ€è¿‘ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å¤‰æ›´ã‚’ç¢ºèªã—ã¦ãã ã•ã„'
            })

        # ç–‘ã‚ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        if contains_suspicious_patterns(package_info):
            security_issues.append({
                'type': 'suspicious_behavior',
                'package': package_name,
                'severity': 'high',
                'patterns': package_info['suspicious_patterns'],
                'recommendation': 'ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ç›£æŸ»ã—ã¦ãã ã•ã„'
            })

    return security_issues

def check_typosquatting(package_name):
    """
    ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åãŒã‚¿ã‚¤ãƒã‚¹ã‚¯ãƒ¯ãƒƒãƒ†ã‚£ãƒ³ã‚°ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    """
    common_packages = [
        'react', 'express', 'lodash', 'axios', 'webpack',
        'babel', 'jest', 'typescript', 'eslint', 'prettier'
    ]

    for legit_package in common_packages:
        distance = levenshtein_distance(package_name.lower(), legit_package)
        if 0 < distance <= 2:  # è¿‘ã„ãŒå®Œå…¨ä¸€è‡´ã§ã¯ãªã„
            return {
                'suspicious': True,
                'similar_packages': [legit_package],
                'distance': distance
            }

    return {'suspicious': False}
```

### 7. è‡ªå‹•ä¿®å¾©

è‡ªå‹•ä¿®æ­£ã‚’ç”Ÿæˆï¼š

**æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**
```bash
#!/bin/bash
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£ã§ä¾å­˜é–¢ä¿‚ã‚’è‡ªå‹•æ›´æ–°

echo "ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"
echo "========================"

# NPM/Yarnæ›´æ–°
if [ -f "package.json" ]; then
    echo "ğŸ“¦ NPMä¾å­˜é–¢ä¿‚ã‚’æ›´æ–°ä¸­..."

    # ç›£æŸ»ã¨è‡ªå‹•ä¿®æ­£
    npm audit fix --force

    # ç‰¹å®šã®è„†å¼±ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’æ›´æ–°
    npm update package1@^2.0.0 package2@~3.1.0

    # ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    npm test

    if [ $? -eq 0 ]; then
        echo "âœ… NPMæ›´æ–°æˆåŠŸ"
    else
        echo "âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—ã€å…ƒã«æˆ»ã—ã¦ã„ã¾ã™..."
        git checkout package-lock.json
    fi
fi

# Pythonæ›´æ–°
if [ -f "requirements.txt" ]; then
    echo "ğŸ Pythonä¾å­˜é–¢ä¿‚ã‚’æ›´æ–°ä¸­..."

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
    cp requirements.txt requirements.txt.backup

    # è„†å¼±ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’æ›´æ–°
    pip-compile --upgrade-package package1 --upgrade-package package2

    # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ
    pip install -r requirements.txt --dry-run

    if [ $? -eq 0 ]; then
        echo "âœ… Pythonæ›´æ–°æˆåŠŸ"
    else
        echo "âŒ æ›´æ–°å¤±æ•—ã€å…ƒã«æˆ»ã—ã¦ã„ã¾ã™..."
        mv requirements.txt.backup requirements.txt
    fi
fi
```

**ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆç”Ÿæˆ**
```python
def generate_dependency_update_pr(updates):
    """
    ä¾å­˜é–¢ä¿‚æ›´æ–°ã§PRã‚’ç”Ÿæˆ
    """
    pr_body = f"""
## ğŸ”’ ä¾å­˜é–¢ä¿‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ›´æ–°

ã“ã®PRã¯ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã¨å¤ã„ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«å¯¾å¿œã™ã‚‹ãŸã‚ã«{len(updates)}å€‹ã®ä¾å­˜é–¢ä¿‚ã‚’æ›´æ–°ã—ã¾ã™ã€‚

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£ ({sum(1 for u in updates if u['has_security'])})

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ç¾åœ¨ | æ›´æ–°å¾Œ | æ·±åˆ»åº¦ | CVE |
|---------|---------|---------|----------|-----|
"""

    for update in updates:
        if update['has_security']:
            pr_body += f"| {update['package']} | {update['current']} | {update['target']} | {update['severity']} | {', '.join(update['cves'])} |\n"

    pr_body += """

### ãã®ä»–ã®æ›´æ–°

| ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | ç¾åœ¨ | æ›´æ–°å¾Œ | ã‚¿ã‚¤ãƒ— | çµŒéæ—¥æ•° |
|---------|---------|---------|------|-----|
"""

    for update in updates:
        if not update['has_security']:
            pr_body += f"| {update['package']} | {update['current']} | {update['target']} | {update['type']} | {update['age_days']} æ—¥ |\n"

    pr_body += """

### ãƒ†ã‚¹ãƒˆ
- [ ] ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒåˆæ ¼
- [ ] ç ´å£Šçš„å¤‰æ›´ã¯ç‰¹å®šã•ã‚Œã¦ã„ã¾ã›ã‚“
- [ ] ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºã¸ã®å½±éŸ¿ã‚’ç¢ºèªæ¸ˆã¿

### ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã«å¯¾å¿œæ¸ˆã¿
- [ ] ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚’ç¶­æŒ
- [ ] äºˆæœŸã—ãªã„ä¾å­˜é–¢ä¿‚ã¯è¿½åŠ ã•ã‚Œã¦ã„ã¾ã›ã‚“
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¸ã®å½±éŸ¿ã‚’è©•ä¾¡æ¸ˆã¿

cc @security-team
"""

    return {
        'title': f'chore(deps): {len(updates)}å€‹ã®ä¾å­˜é–¢ä¿‚ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ›´æ–°',
        'body': pr_body,
        'branch': f'deps/security-update-{datetime.now().strftime("%Y%m%d")}',
        'labels': ['dependencies', 'security']
    }
```

### 8. ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

ç¶™ç¶šçš„ãªä¾å­˜é–¢ä¿‚ç›£è¦–ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼š

**GitHub Actionsãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**
```yaml
name: Dependency Audit

on:
  schedule:
    - cron: '0 0 * * *'  # æ¯æ—¥
  push:
    paths:
      - 'package*.json'
      - 'requirements.txt'
      - 'Gemfile*'
      - 'go.mod'
  workflow_dispatch:

jobs:
  security-audit:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Run NPM Audit
      if: hashFiles('package.json')
      run: |
        npm audit --json > npm-audit.json
        if [ $(jq '.vulnerabilities.total' npm-audit.json) -gt 0 ]; then
          echo "::error::Found $(jq '.vulnerabilities.total' npm-audit.json) vulnerabilities"
          exit 1
        fi

    - name: Run Python Safety Check
      if: hashFiles('requirements.txt')
      run: |
        pip install safety
        safety check --json > safety-report.json

    - name: Check Licenses
      run: |
        npx license-checker --json > licenses.json
        python scripts/check_license_compliance.py

    - name: Create Issue for Critical Vulnerabilities
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const audit = require('./npm-audit.json');
          const critical = audit.vulnerabilities.critical;

          if (critical > 0) {
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ğŸš¨ ${critical}å€‹ã®é‡å¤§ãªè„†å¼±æ€§ã‚’ç™ºè¦‹`,
              body: 'ä¾å­˜é–¢ä¿‚ç›£æŸ»ã§é‡å¤§ãªè„†å¼±æ€§ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚è©³ç´°ã¯ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚',
              labels: ['security', 'dependencies', 'critical']
            });
          }
```

## å‡ºåŠ›å½¢å¼

1. **ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼**: é«˜ãƒ¬ãƒ™ãƒ«ã®ãƒªã‚¹ã‚¯è©•ä¾¡ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³é …ç›®
2. **è„†å¼±æ€§ãƒ¬ãƒãƒ¼ãƒˆ**: æ·±åˆ»åº¦è©•ä¾¡ã‚’å«ã‚€è©³ç´°ãªCVEåˆ†æ
3. **ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹**: äº’æ›æ€§ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã¨æ³•çš„ãƒªã‚¹ã‚¯
4. **æ›´æ–°æ¨å¥¨äº‹é …**: åŠ´åŠ›è¦‹ç©ã‚‚ã‚Šã‚’å«ã‚€å„ªå…ˆé †ä½ä»˜ããƒªã‚¹ãƒˆ
5. **ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³åˆ†æ**: ã‚¿ã‚¤ãƒã‚¹ã‚¯ãƒ¯ãƒƒãƒ†ã‚£ãƒ³ã‚°ã¨ãƒã‚¤ã‚¸ãƒ£ãƒƒã‚¯ãƒªã‚¹ã‚¯
6. **ä¿®å¾©ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: è‡ªå‹•æ›´æ–°ã‚³ãƒãƒ³ãƒ‰ã¨PRç”Ÿæˆ
7. **ã‚µã‚¤ã‚ºå½±éŸ¿ãƒ¬ãƒãƒ¼ãƒˆ**: ãƒãƒ³ãƒ‰ãƒ«ã‚µã‚¤ã‚ºåˆ†æã¨æœ€é©åŒ–ã®ãƒ’ãƒ³ãƒˆ
8. **ç›£è¦–ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**: ç¶™ç¶šçš„ã‚¹ã‚­ãƒ£ãƒ³ã®ãŸã‚ã®CI/CDçµ±åˆ

å®‰å…¨ã§ã€ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã«æº–æ‹ ã—ãŸã€åŠ¹ç‡çš„ãªä¾å­˜é–¢ä¿‚ç®¡ç†ã®ç¶­æŒã«å½¹ç«‹ã¤å®Ÿè¡Œå¯èƒ½ãªã‚¤ãƒ³ã‚µã‚¤ãƒˆã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚
